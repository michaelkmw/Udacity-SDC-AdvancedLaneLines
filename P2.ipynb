{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: Advanced Lane Finding\n",
    "***\n",
    "This project improves upon the previous lane finding pipeline with advanced techniques to detect lane lines in a variety of lighting and shading conditions. The pipeline consists of the following steps:\n",
    "\n",
    "1. **Camera Calibration**\n",
    "    - In order to correct camera distortion in the test images and videos, camera calibration must first be performed using images of chessboard pattern. The resulting camera matrix and distortion coefficients can then be applied to correct for distortion in the test images and videos.\n",
    "\n",
    "1. **Gradients and Color Thresholding**\n",
    "    - A variety of gradient threshold and color thresholding algorithm can then be applied to the test images and videos. The goal is to process an image such that the lane lines can be easily isolated from other features in a binary image under a variety of lighting and shading conditions.\n",
    "\n",
    "1. **Perspective Transform**\n",
    "    - Using perspective transform, images and videos of the car's dashboard view can be transformed into bird's-eye view. This allows the warpped image to be further processed to identify the curvature of the road.\n",
    "    \n",
    "1. **Lane Finding**\n",
    "    - With a bird's-eye view image of the road, lane markings can then be identified using sliding window algorithm or searching from previously identified lane markings.\n",
    "    \n",
    "1. **Curvature Measurement**\n",
    "    - Once the lane markings have been identified, radius of curvature of the lane markings as well as the position of the vehicle with respect to the center (assuming the camera is mounted at the center of the car) can then be computed.\n",
    "    \n",
    "1. **Reverse Perspective Transform**\n",
    "    - Once the lane markings have been identified, the identified lane lines can then be projected back onto the car's dashboard view via the perspective transform matrix computed in the previous steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # how many iteration was the line not detected?\n",
    "        self.detected_counter = 0  \n",
    "        # maximum number of iteration that line not detected before performing sliding window search\n",
    "        self.max_detected_counter = 25 \n",
    "        # maximum number of x values to store from previous frame\n",
    "        self.maxframe = 50\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes in a series of calibration image from camera_cal\n",
    "# folder and compute the camera matrix and distortion coefficients.\n",
    "#\n",
    "# Input: none\n",
    "#\n",
    "# Output: mtx - camera matrix\n",
    "#         dist - distortion coefficients\n",
    "\n",
    "def CameraCalibration():\n",
    "    # Prepare object points on a 9x6 chessboard pattern. Note that a 9x5\n",
    "    # is chosen instead because findChessboardCorners() cannot detect\n",
    "    # all 9x6 grid in some of the close-up images \n",
    "    nx = 9\n",
    "    ny = 5\n",
    "    \n",
    "    # Arrays to store object points and image points from calibration images\n",
    "    objpoints = [] # 3D points in real world space\n",
    "    imgpoints = [] # 2D points in image plane\n",
    "    \n",
    "    # Prepare object points e.g. (0,0,0), (1,0,0)... (x,y,z), where z is 0\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "    \n",
    "    # Read a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "    \n",
    "    for fname in images:\n",
    "        img = mpimg.imread(fname)\n",
    "    \n",
    "        ## Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        ## Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "    \n",
    "        # If corners are found, add object points and image points to the arrays\n",
    "        if ret == True:\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "    \n",
    "            # Draw and display the corners\n",
    "            #cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "    \n",
    "    # Compute camera matrix and distortion coefficients from object points\n",
    "    # and image points arrays\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "        \n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gradients Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes in an image and apply threshold on the grayscale\n",
    "# gradient in either x or y direction \n",
    "#\n",
    "# Input: img - image\n",
    "#        orient - 'x' or 'y'\n",
    "#        sobel_kernel - kernel size of the sobel operator\n",
    "#        thresh - lower and higher bound for the gradient threshold\n",
    "#\n",
    "# Output: grad_binary - binary image that is gradient thresholded\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    if orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    sobel_binary = np.zeros_like(scaled_sobel)\n",
    "    sobel_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    grad_binary = sobel_binary\n",
    "    return grad_binary\n",
    "\n",
    "# This function takes in an image and apply threshold on the grayscale\n",
    "# gradient in terms of magnitude of gradient\n",
    "#\n",
    "# Input: img - image\n",
    "#        sobel_kernel - kernel size of the sobel operator\n",
    "#        thresh - lower and higher bound for the gradient threshold\n",
    "#\n",
    "# Output: mag_binary - binary image that is gradient thresholded\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude\n",
    "    sobelxy = (pow(sobelx, 2) + pow(sobely, 2))**0.5\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*sobelxy/np.max(sobelxy))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    sobel_binary = np.zeros_like(scaled_sobel)\n",
    "    sobel_binary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    mag_binary = sobel_binary\n",
    "    return mag_binary\n",
    "\n",
    "# This function takes in an image and apply threshold on the grayscale\n",
    "# gradient in terms of direction of gradient\n",
    "#\n",
    "# Input: img - image\n",
    "#        sobel_kernel - kernel size of the sobel operator\n",
    "#        thresh - lower and higher bound for the gradient threshold\n",
    "#\n",
    "# Output: dir_binary - binary image that is gradient thresholded\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    dir_sobel = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    sobel_binary = np.zeros_like(dir_sobel)\n",
    "    sobel_binary[(dir_sobel >= thresh[0]) & (dir_sobel <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    dir_binary = sobel_binary\n",
    "    return dir_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Colour Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes in an image and apply threshold on the grayscale\n",
    "# gradient in terms of R-channel intensity in RGB color space\n",
    "#\n",
    "# Input: img - image\n",
    "#        thresh - lower and higher bound for the color threshold\n",
    "#\n",
    "# Output: binary_output - binary image that is color thresholded\n",
    "def rgb_select(img, thresh=(0,255)):\n",
    "    # 1) Apply a threshold to the R channel\n",
    "    # 2) Return a binary image of threshold result\n",
    "    R = img[:,:,0]\n",
    "    binary_output = np.zeros_like(R)\n",
    "    binary_output[(R > thresh[0]) & (R <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "# This function takes in an image and apply threshold on the grayscale\n",
    "# gradient in terms of S-channel intensity in HSV color space\n",
    "#\n",
    "# Input: img - image\n",
    "#        thresh - lower and higher bound for the color threshold\n",
    "#\n",
    "# Output: binary_output - binary image that is color thresholded\n",
    "def hsv_select(img, thresh=(0,255)):\n",
    "    # 1) Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    H = hsv[:,:,0]\n",
    "    S = hsv[:,:,1]\n",
    "    V = hsv[:,:,2]\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    # 3) Return a binary image of threshold result\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "# This function takes in an image and apply threshold on the grayscale\n",
    "# gradient in terms of S-channel intensity in HLS color space\n",
    "#\n",
    "# Input: img - image\n",
    "#        thresh - lower and higher bound for the color threshold\n",
    "#\n",
    "# Output: binary_output - binary image that is color thresholded\n",
    "def hls_select(img, thresh=(0,255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    H = hls[:,:,0]\n",
    "    L = hls[:,:,1]\n",
    "    S = hls[:,:,2]\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    # 3) Return a binary image of threshold result\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The straight lines images in the \"test_images\" folder are used to define the\n",
    "# source points for perspective transform. To do so, the images are first\n",
    "# undistorted using the camera matrix and distortion coefficients computed in\n",
    "# the Camera Calibration section. Then, the source points are handpicked in the\n",
    "# images. Finally, a perspective transform is performed on those images, and\n",
    "# straight lines are overlaid on top of the images to verify that the transform\n",
    "# is working as expected.\n",
    "\n",
    "# The source points are defined by manually locating the pixel of the bottom\n",
    "# and top ends of the lane lines in the images. The x-coordinates of the\n",
    "# source points are manually tuned by examining the straightness of the warped\n",
    "# image\n",
    "#\n",
    "# straight_lines1\n",
    "# (205, 720), (620, 435), (1105, 720), (655, 435)\n",
    "# straight_lines2\n",
    "# (220, 720), (620, 430), (1110, 720), (660, 435)\n",
    "\n",
    "def warp(img):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    # Four source coordinates\n",
    "    src = np.float32(\n",
    "        [[203, 720],\n",
    "         [581, 460],\n",
    "         [702, 460],\n",
    "         [1099, 720]])\n",
    "    # Four desired coordinates\n",
    "    dst = np.float32(\n",
    "        [[350, 720],\n",
    "         [350, 0],\n",
    "         [950, 0],\n",
    "         [950, 720]])\n",
    "\n",
    "    # Compute the perspective transform, M\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    # Compute the inverse perspective transform, Minv\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    # Create warped image - uses linear interpolation\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)#, borderMode=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    return M, Minv, warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes in second-order polynomial coefficients\n",
    "# and computes the radius of curvature as well as the distance\n",
    "# from the vehicle center at the bottom of the image\n",
    "#\n",
    "# Input: left_fit - polynomial coefficients of fitted curve\n",
    "#        right_fit - polynomial coefficients of fitted curve\n",
    "#\n",
    "# Output: left_pos_diff - distance of left curve from vehicle center (m)\n",
    "#         right_pos_diff - distance of right curve from vehicle center (m)\n",
    "#         left_curverad - radius of curvature of left curve (m)\n",
    "#         right_curverad - radius of curvature of right curve (m)\n",
    "def measure_curvature_real(left_fit, right_fit):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/600 # meters per pixel in x dimension\n",
    "    \n",
    "    # Define y-value where we want radius of curvature and lane position\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = 720\n",
    "    \n",
    "    left_fit_cr = np.copy(left_fit)\n",
    "    right_fit_cr = np.copy(right_fit)\n",
    "    \n",
    "    # Compute the distance between lane and vehicle center\n",
    "    # Assuming the image center is aligned with vehicle center\n",
    "    # Vehicle center pixel is 1280/2 = 640\n",
    "    left_base_pos = left_fit_cr[0] * y_eval**2 + left_fit_cr[1] * y_eval + left_fit_cr[2]\n",
    "    right_base_pos = right_fit_cr[0] * y_eval**2 + right_fit_cr[1] * y_eval + right_fit_cr[2]\n",
    "    \n",
    "    left_pos_diff = (left_base_pos - 640) * xm_per_pix\n",
    "    right_pos_diff = (right_base_pos - 640) * xm_per_pix\n",
    "    \n",
    "    # Calculates the curvature of polynomial functions in meters.\n",
    "    # Convert polynomial coefficient from pixel to m    \n",
    "    left_fit_cr[0] *= (xm_per_pix / ym_per_pix**2)\n",
    "    left_fit_cr[1] *= (xm_per_pix / ym_per_pix)\n",
    "    \n",
    "    right_fit_cr[0] *= (xm_per_pix / ym_per_pix**2)\n",
    "    right_fit_cr[1] *= (xm_per_pix / ym_per_pix)\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "            \n",
    "    return left_pos_diff, right_pos_diff, left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Lane Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in the x and y pixel of the identified\n",
    "# lane marking and attempt to fit a second-order polynomial\n",
    "# over them\n",
    "#\n",
    "# This function also performs sanity check on the fitted curve\n",
    "# for the following:\n",
    "# - left and right curve are separated by approximately the \n",
    "#   right distance horizontally\n",
    "# - left and right curve are roughly parallel\n",
    "#\n",
    "# Input: img_shape - shapes of image\n",
    "#        leftx - array of x pixel values of left lane\n",
    "#        lefty - array of y pixel values of left lane\n",
    "#        rightx - array of x pixel values of right lane\n",
    "#        righty - array of y pixel values of right lane\n",
    "#\n",
    "# Output: left_fit - polynomial coefficients of fitted curve\n",
    "#         right_fit - polynomial coefficients of fitted curve\n",
    "#         left_fitx - array of x value of left curve\n",
    "#         right_fitx - array of x value of right curve\n",
    "#         ploty - array of y value of both curves\n",
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "    # Fit a second order polynomial to each with np.polyfit()\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    # Calc both polynomials using ploty, left_fit and right_fit\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        left_lane.detected = True\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        left_lane.detected = False\n",
    "    try:\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        right_lane.detected = True\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_lane.detected = False\n",
    "\n",
    "    left_lane.current_fit = np.copy(left_fit)\n",
    "    right_lane.current_fit = np.copy(right_fit)\n",
    "    \n",
    "    # Compute radius of curvature of left and right lanes of current frame\n",
    "    left_pos_diff, right_pos_diff, left_curverad, right_curverad = \\\n",
    "        measure_curvature_real(left_lane.current_fit, right_lane.current_fit)\n",
    "\n",
    "    ## Sanity check to make sure the fitted curves are correct\n",
    "    ## 1 - checking for curvature is difficult and error prone in straight line\n",
    "    #curvature_diff = np.absolute(left_curverad - right_curverad)\n",
    "    #diff_perc = np.maximum(curvature_diff/left_curverad, curvature_diff/right_curverad)\n",
    "    #if diff_perc > 0.5:\n",
    "    #    left_lane.detected = False\n",
    "    #    right_lane.detected = False\n",
    "    # 2 - left and right curve are separated by approximately the \n",
    "    #   right distance horizontally\n",
    "    lane_separation = right_pos_diff - left_pos_diff\n",
    "    if lane_separation < 3.0 or lane_separation > 5.0:\n",
    "        left_lane.detected = False\n",
    "        right_lane.detected = False\n",
    "    # 3 - checking for parallel lines is difficult and error prone in straight line    \n",
    "    \n",
    "    # Compute the averaged left and right curve fits over previous n iteration\n",
    "    if left_lane.detected:\n",
    "        # Check if maximum storage of x value of fitted line is reached\n",
    "        # If so, remove the first element\n",
    "        if len(left_lane.recent_xfitted) == left_lane.maxframe:\n",
    "            left_lane.recent_xfitted.pop(0)\n",
    "        left_lane.recent_xfitted.append(left_fitx)\n",
    "        \n",
    "        # Compute the average x value of fitted line over previous n iteration\n",
    "        elemsum = np.zeros_like(left_lane.recent_xfitted[0])\n",
    "        for element in left_lane.recent_xfitted:\n",
    "            elemsum += element\n",
    "        left_lane.bestx = elemsum / len(left_lane.recent_xfitted)\n",
    "        \n",
    "        # Compute the polynomial coefficients averaged over the last n iteration\n",
    "        left_lane.best_fit = np.polyfit(ploty, left_lane.bestx, 2)\n",
    "\n",
    "    if right_lane.detected:\n",
    "        # Check if maximum storage of x value of fitted line is reached\n",
    "        # If so, remove the first element\n",
    "        if len(right_lane.recent_xfitted) == right_lane.maxframe:\n",
    "            right_lane.recent_xfitted.pop(0)\n",
    "        right_lane.recent_xfitted.append(right_fitx)\n",
    "        \n",
    "        # Compute the average x value of fitted line over previous n iteration\n",
    "        elemsum = np.zeros_like(right_lane.recent_xfitted[0])\n",
    "        for element in right_lane.recent_xfitted:\n",
    "            elemsum += element\n",
    "        right_lane.bestx = elemsum / len(right_lane.recent_xfitted)\n",
    "        \n",
    "        # Compute the polynomial coefficients averaged over the last n iteration\n",
    "        right_lane.best_fit = np.polyfit(ploty, right_lane.bestx, 2)\n",
    "\n",
    "    # Compute radius of curvature of averaged left and right curve fit\n",
    "    if (left_lane.recent_xfitted or right_lane.recent_xfitted):\n",
    "        left_pos_diff, right_pos_diff, left_curverad, right_curverad = \\\n",
    "            measure_curvature_real(left_lane.best_fit, right_lane.best_fit)\n",
    "\n",
    "    left_lane.line_base_pos = np.copy(left_pos_diff)\n",
    "    right_lane.line_base_pos = np.copy(right_pos_diff)\n",
    "    left_lane.radius_of_curvature = np.copy(left_curverad)\n",
    "    right_lane.radius_of_curvature = np.copy(right_curverad) \n",
    "    \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, ploty\n",
    "\n",
    "# This function takes in an image and determine the location of\n",
    "# the lane lines through finding peaks of histogram of the bottom\n",
    "# half of binary image then performing sliding window search\n",
    "# towards the top half of the image\n",
    "#\n",
    "# Input: binary_warped - image\n",
    "#\n",
    "# Output: left_fitx - array of x value of left curve\n",
    "#         right_fitx - array of x value of right curve\n",
    "#         ploty - array of y value of both curves\n",
    "#         out_img - image\n",
    "def sliding_search(binary_warped):\n",
    "    # Grab only the bottom half of the image\n",
    "    # Lane lines are likely to be mostly vertical nearest to the car\n",
    "    bottom_half = binary_warped[binary_warped.shape[0]//2:,:]\n",
    "    \n",
    "    # Sum across image pixels vertically - make sure to set an `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero (i.e. activated) pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzerox >= win_xleft_low) & (nonzerox <= win_xleft_high) &\n",
    "                          (nonzeroy >= win_y_low) & (nonzeroy <= win_y_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzerox >= win_xright_low) & (nonzerox <= win_xright_high) &\n",
    "                           (nonzeroy >= win_y_low) & (nonzeroy <= win_y_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    \n",
    "    # Fit new polynomial\n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "                           \n",
    "    return left_fitx, right_fitx, ploty, out_img\n",
    "\n",
    "# This function takes in an image and determine the location of\n",
    "# the lane lines through searching the neighbourhood of the\n",
    "# polynomial fitted to the left and right lane of the previous\n",
    "# frame in the video\n",
    "#\n",
    "# Input: binary_warped - image\n",
    "#\n",
    "# Output: result - image\n",
    "def search_around_poly(binary_warped):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 50\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    left_fit = np.copy(left_lane.current_fit)\n",
    "    right_fit = np.copy(right_lane.current_fit)\n",
    "    \n",
    "    ### Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    ## End visualization steps ##\n",
    "    \n",
    "    return left_fitx, right_fitx, ploty, result\n",
    "\n",
    "def search_lane(binary_warped):    \n",
    "    if (left_lane.detected == False) or (right_lane.detected == False):\n",
    "        left_lane.detected_counter += 1\n",
    "        \n",
    "    # Start with sliding window search to identify the lane lines if the following is True\n",
    "    # 1. left and right lanes haven't been detected for certain number of frames\n",
    "    # 2. left and right lanes have never been fitted (start of video)\n",
    "    # Else, perform a lane search using the fitted polynomial\n",
    "    if (left_lane.detected_counter > left_lane.max_detected_counter) or \\\n",
    "       (right_lane.detected_counter > right_lane.max_detected_counter) or \\\n",
    "       (not left_lane.recent_xfitted or not right_lane.recent_xfitted):\n",
    "        left_fitx, right_fitx, ploty, out_img = sliding_search(binary_warped)\n",
    "    else:\n",
    "        left_fitx, right_fitx, ploty, out_img = search_around_poly(binary_warped)\n",
    "    if (left_lane.detected == True) and (right_lane.detected == True):\n",
    "        left_lane.detected_counter = 0\n",
    "        right_lane.detected_counter = 0\n",
    "    return left_fitx, right_fitx, ploty, out_img "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Image Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "dirs = os.listdir(\"test_images/\")\n",
    "\n",
    "### Camera Calibration\n",
    "mtx, dist = CameraCalibration()\n",
    "\n",
    "for file in dirs:  \n",
    "    # Instantiate left and right lane using Line class\n",
    "    left_lane = Line()\n",
    "    right_lane = Line()\n",
    "    \n",
    "    ### Undistort the image\n",
    "    image = mpimg.imread(\"test_images/\"+file)\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    plt.imsave(\"output_images/\"+\"undist_\"+os.path.basename(file), undist, format='png')\n",
    "    \n",
    "    ### Grandient Thresholding\n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 15 # Choose a larger odd number to smooth gradient measurements\n",
    "    min_dir = 40 # Minimum lane angle from horizontal to be detected\n",
    "    max_dir = 75 # Maximum lane angle from horizontal to be detected\n",
    "    grad_low_threshold = 30 # Minimum grayscale gradient intensity to be detected\n",
    "    grad_high_threshold = 100 # Maximum grayscale gradient intensity to be detected\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(undist, orient='x', sobel_kernel=ksize, thresh=(grad_low_threshold, grad_high_threshold))\n",
    "\n",
    "    grad_combined = np.zeros_like(gradx)\n",
    "    grad_combined[(gradx == 1)] = 1\n",
    "    plt.imsave(\"output_images/\"+\"grad_\"+os.path.basename(file), grad_combined, format='png', cmap='gray')\n",
    "    \n",
    "    ### Color Thresholding\n",
    "    hsv_low_threshold = 120 # Minimum satuation intensity to be detected\n",
    "    hsv_high_threshold = 255 # Maximum satuation intensity to be detected\n",
    "\n",
    "    hls_low_threshold = 120 # Minimum satuation intensity to be detected\n",
    "    hls_high_threshold = 255 # Maximum satuation intensity to be detected\n",
    "\n",
    "    rgb_low_threshold = 200 # Minimum R value to be detected\n",
    "    rgb_high_threshold = 255 # Maximum R value to be detected\n",
    "\n",
    "    # apply S-channel thresholding in HLS color space\n",
    "    hls_binary = hls_select(undist, thresh=(hls_low_threshold, hls_high_threshold))\n",
    "    \n",
    "    # apply R-channel thresholding in RGB color space\n",
    "    R_binary = rgb_select(undist, thresh=(rgb_low_threshold, rgb_high_threshold))\n",
    "    \n",
    "    color_binary = np.zeros_like(hls_binary)\n",
    "    color_binary[(hls_binary == 1) & (R_binary == 1)] = 1\n",
    "    plt.imsave(\"output_images/\"+\"color_\"+os.path.basename(file), color_binary, format='png', cmap='gray')\n",
    "\n",
    "    ### Combined Thresholding\n",
    "    # combine color and gradient thresholded images\n",
    "    combined_binary = np.zeros_like(color_binary)\n",
    "    combined_binary[(color_binary == 1) | (grad_combined == 1)] = 1\n",
    "    \n",
    "    # color visualization of the contribution of color and gradient threshold\n",
    "    visual_binary = np.dstack((color_binary, grad_combined, np.zeros_like(color_binary))) * 255\n",
    "    plt.imsave(\"output_images/\"+\"combined_\"+os.path.basename(file), visual_binary, format='png')\n",
    "    \n",
    "    ### Perspective Transform\n",
    "    M, Minv, warped = warp(combined_binary)\n",
    "    plt.imsave(\"output_images/\"+\"warped_\"+os.path.basename(file), warped, format='png', cmap='gray')\n",
    "    \n",
    "    ### Lane Finding\n",
    "    left_fitx, right_fitx, ploty, out_img = sliding_search(warped)\n",
    "    \n",
    "    # Generate a polygon to illustrate the fitted curve\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    margin = 5\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(out_img, np.int_([left_line_pts]), (255 ,255, 0))\n",
    "    cv2.fillPoly(out_img, np.int_([right_line_pts]), (255 ,255, 0))\n",
    "    \n",
    "    plt.imsave(\"output_images/\"+\"detected_\"+os.path.basename(file), out_img, format='png')\n",
    "\n",
    "    ### Drawing Lane on image\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    ### Inverse Perspective Transform\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0, dtype=cv2.CV_8U)\n",
    "    \n",
    "    ### Display lane information on image\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10,30)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 2\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,60)\n",
    "    text = 'Lane Curvature: {:4.2f}'.format((left_lane.radius_of_curvature + right_lane.radius_of_curvature)/2)\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,90)\n",
    "    dist_to_center = right_lane.line_base_pos + left_lane.line_base_pos\n",
    "    if dist_to_center >= 0.0:\n",
    "        text = 'Vehicle is {:1.2f}m left of center'.format(np.absolute(dist_to_center))\n",
    "    else:\n",
    "        text = 'Vehicle is {:1.2f}m right of center'.format(np.absolute(dist_to_center))\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "\n",
    "    plt.imsave(\"output_images/\"+\"final_\"+os.path.basename(file), result, format='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ### Undistort the image\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    ### Grandient Thresholding\n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 15 # Choose a larger odd number to smooth gradient measurements\n",
    "    min_dir = 40 # Minimum lane angle from horizontal to be detected\n",
    "    max_dir = 75 # Maximum lane angle from horizontal to be detected\n",
    "    grad_low_threshold = 30 # Minimum grayscale gradient intensity to be detected\n",
    "    grad_high_threshold = 100 # Maximum grayscale gradient intensity to be detected\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(undist, orient='x', sobel_kernel=ksize, thresh=(grad_low_threshold, grad_high_threshold))\n",
    "\n",
    "    grad_combined = np.zeros_like(gradx)\n",
    "    grad_combined[(gradx == 1)] = 1\n",
    "    \n",
    "    ### Color Thresholding\n",
    "    hsv_low_threshold = 120 # Minimum satuation intensity to be detected\n",
    "    hsv_high_threshold = 255 # Maximum satuation intensity to be detected\n",
    "\n",
    "    hls_low_threshold = 120 # Minimum satuation intensity to be detected\n",
    "    hls_high_threshold = 255 # Maximum satuation intensity to be detected\n",
    "\n",
    "    rgb_low_threshold = 200 # Minimum R value to be detected\n",
    "    rgb_high_threshold = 255 # Maximum R value to be detected\n",
    "\n",
    "    # apply S-channel thresholding in HLS color space\n",
    "    hls_binary = hls_select(undist, thresh=(hls_low_threshold, hls_high_threshold))\n",
    "    \n",
    "    # apply R-channel thresholding in RGB color space\n",
    "    R_binary = rgb_select(undist, thresh=(rgb_low_threshold, rgb_high_threshold))\n",
    "    \n",
    "    color_binary = np.zeros_like(hls_binary)\n",
    "    color_binary[(hls_binary == 1) & (R_binary == 1)] = 1\n",
    "\n",
    "    ### Combined Thresholding\n",
    "    # combine color and gradient thresholded images\n",
    "    combined_binary = np.zeros_like(color_binary)\n",
    "    combined_binary[(color_binary == 1) | (grad_combined == 1)] = 1\n",
    "    \n",
    "    ### Perspective Transform\n",
    "    M, Minv, warped = warp(combined_binary)\n",
    "    \n",
    "    ### Lane Finding\n",
    "    left_fitx, right_fitx, ploty, out_img = search_lane(warped)\n",
    "\n",
    "    ### Drawing Lane on image\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0, dtype=cv2.CV_8U)\n",
    "\n",
    "    ### Display lane information on image\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10,30)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 2\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,60)\n",
    "    text = 'Lane Curvature: {:4.2f}'.format((left_lane.radius_of_curvature + right_lane.radius_of_curvature)/2)\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,90)\n",
    "    dist_to_center = right_lane.line_base_pos + left_lane.line_base_pos\n",
    "    if dist_to_center >= 0.0:\n",
    "        text = 'Vehicle is {:1.2f}m left of center'.format(np.absolute(dist_to_center))\n",
    "    else:\n",
    "        text = 'Vehicle is {:1.2f}m right of center'.format(np.absolute(dist_to_center))\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def process_grad(image):\n",
    "    ### Undistort the image\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    ### Grandient Thresholding\n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 15 # Choose a larger odd number to smooth gradient measurements\n",
    "    min_dir = 40 # Minimum lane angle from horizontal to be detected\n",
    "    max_dir = 75 # Maximum lane angle from horizontal to be detected\n",
    "    grad_low_threshold = 30 # Minimum grayscale gradient intensity to be detected\n",
    "    grad_high_threshold = 100 # Maximum grayscale gradient intensity to be detected\n",
    "\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(undist, orient='x', sobel_kernel=ksize, thresh=(grad_low_threshold, grad_high_threshold))\n",
    "\n",
    "    grad_combined = np.zeros_like(gradx)\n",
    "    grad_combined[(gradx == 1)] = 1\n",
    "    \n",
    "    ### Color Thresholding\n",
    "    hsv_low_threshold = 120 # Minimum satuation intensity to be detected\n",
    "    hsv_high_threshold = 255 # Maximum satuation intensity to be detected\n",
    "\n",
    "    hls_low_threshold = 120 # Minimum satuation intensity to be detected\n",
    "    hls_high_threshold = 255 # Maximum satuation intensity to be detected\n",
    "\n",
    "    rgb_low_threshold = 200 # Minimum R value to be detected\n",
    "    rgb_high_threshold = 255 # Maximum R value to be detected\n",
    "\n",
    "    # apply S-channel thresholding in HLS color space\n",
    "    hls_binary = hls_select(undist, thresh=(hls_low_threshold, hls_high_threshold))\n",
    "    \n",
    "    # apply R-channel thresholding in RGB color space\n",
    "    R_binary = rgb_select(undist, thresh=(rgb_low_threshold, rgb_high_threshold))\n",
    "    \n",
    "    color_binary = np.zeros_like(hls_binary)\n",
    "    color_binary[(hls_binary == 1) & (R_binary == 1)] = 1\n",
    "\n",
    "    ### Combined Thresholding\n",
    "    # combine color and gradient thresholded images\n",
    "    combined_binary = np.zeros_like(color_binary)\n",
    "    combined_binary[(color_binary == 1) | (grad_combined == 1)] = 1\n",
    "    \n",
    "    ### Perspective Transform\n",
    "    M, Minv, warped = warp(combined_binary)\n",
    "    \n",
    "    ### Lane Finding\n",
    "    left_fitx, right_fitx, ploty, out_img = search_lane(warped)\n",
    "\n",
    "    ### Drawing Lane on image\n",
    "    # Create an image to draw the lines on\n",
    "    grad_zero = np.zeros_like(combined_binary).astype(np.uint8)\n",
    "    grad_warp = np.dstack((grad_combined, color_binary, grad_zero)) * 255\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(out_img, Minv, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(grad_warp, 1, newwarp, 1, 0, dtype=cv2.CV_8U)\n",
    "\n",
    "    ### Display lane information on image\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10,30)\n",
    "    fontScale              = 1\n",
    "    fontColor              = (255,255,255)\n",
    "    lineType               = 2\n",
    "    \n",
    "    text = 'Left Lane Detected: {}'.format(left_lane.detected)\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,60)\n",
    "    text = 'Left Lane Fit Coef: '\n",
    "    for element in left_lane.current_fit:\n",
    "        text += '{:2.6f} '.format(element)\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,90)\n",
    "    text = 'Left Lane Curvature: {:4.2f}'.format(left_lane.radius_of_curvature)\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,120)\n",
    "    text = 'Right Lane Detected: {}'.format(right_lane.detected)\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,150)\n",
    "    text = 'Right Lane Fit Coef: '\n",
    "    for element in right_lane.current_fit:\n",
    "        text += '{:2.6f} '.format(element)\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,180)\n",
    "    text = 'Right Lane Curvature: {:4.2f}'.format(right_lane.radius_of_curvature)\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    bottomLeftCornerOfText = (10,210)\n",
    "    dist_to_center = right_lane.line_base_pos + left_lane.line_base_pos\n",
    "    if dist_to_center >= 0.0:\n",
    "        text = 'Vehicle is {:1.2f}m left of center'.format(np.absolute(dist_to_center))\n",
    "    else:\n",
    "        text = 'Vehicle is {:1.2f}m right of center'.format(np.absolute(dist_to_center))\n",
    "    cv2.putText(result, text, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|▏                                                                   | 3/1260 [00:00<00:59, 21.18it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video project_video_output.mp4.\n",
      "Moviepy - Writing video project_video_output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready project_video_output.mp4\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "### Camera Calibration\n",
    "mtx, dist = CameraCalibration()\n",
    "\n",
    "# Instantiate left and right lane using Line class\n",
    "left_lane = Line()\n",
    "right_lane = Line()\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "white_output = 'project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,1)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
